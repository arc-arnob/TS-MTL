{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_existing_results(file_path=\"forecasting_results_deep.json\"):\n",
    "    \"\"\"\n",
    "    Load existing results from a JSON file.\n",
    "    Returns an empty dictionary if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "\n",
    "def save_results_to_json(data, file_path=\"secured_forecasting_results.json\"):\n",
    "    \"\"\"\n",
    "    Save the results dictionary to a JSON file, handling NumPy data types.\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle NumPy data types (recursive conversion)\n",
    "    def convert_numpy(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: convert_numpy(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_numpy(i) for i in obj]\n",
    "        elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()  # Convert arrays to lists\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    # Convert data and save to JSON\n",
    "    data = convert_numpy(data)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"✅ Results saved to {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def store_results(dataset_name, horizons, horizon_value, experiment_type, backbone, mae_result, file_path=\"forecasting_results.json\"):\n",
    "    \"\"\"\n",
    "    Store MAE results for a given experiment type (stl_mae, mtl_mae, global_mae) per horizon.\n",
    "\n",
    "    Args:\n",
    "    - dataset_name (str): Name of the dataset (e.g., 'Solar', 'Air Quality').\n",
    "    - horizons (list): List of horizon values (e.g., [1, 2, 4, 8, 16]).\n",
    "    - horizon_value (int): The horizon corresponding to the mae_result provided.\n",
    "    - experiment_type (str): One of ['stl_mae', 'mtl_mae', 'global_mae'].\n",
    "    - backbone (str): Model backbone name (e.g., 'Deep_LSTM', 'simple_transformer').\n",
    "    - mae_result (list): MAE values for the current horizon (list of floats).\n",
    "    - file_path (str): JSON file to store the results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Load existing results\n",
    "    results_dict = load_existing_results(file_path)\n",
    "\n",
    "    # Create dataset entry if it doesn't exist\n",
    "    dataset_key = f\"{dataset_name}_{backbone}\"\n",
    "    if dataset_key not in results_dict:\n",
    "        results_dict[dataset_key] = {\n",
    "            \"horizons\": horizons,\n",
    "            \"mtl\": [[] for _ in horizons],\n",
    "            \"global\": [[] for _ in horizons],\n",
    "            \"independent\": [[] for _ in horizons]\n",
    "        }\n",
    "\n",
    "    # Find index for the given horizon\n",
    "    try:\n",
    "        horizon_index = horizons.index(horizon_value)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"⚠️ Horizon value {horizon_value} not found in {horizons}.\")\n",
    "\n",
    "    # Append the mae_result to the correct horizon\n",
    "    results_dict[dataset_key][experiment_type][horizon_index].extend(mae_result)\n",
    "\n",
    "    # Save updated results\n",
    "    save_results_to_json(results_dict, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ------------------ MODEL COMPONENTS ------------------\n",
    "\n",
    "class TaskSpecificAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TaskSpecificAttention, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, input_dim)\n",
    "        self.residual_fc = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_weights = F.softmax(self.fc(x), dim=-1)\n",
    "        context_vector = torch.tanh(x * attention_weights)\n",
    "        return x + self.residual_fc(context_vector)\n",
    "\n",
    "\n",
    "class SharedGlobalTemporalAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(SharedGlobalTemporalAttention, self).__init__()\n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.final_fc = nn.Linear(hidden_dim, 1)\n",
    "        self.residual_fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Projection layer to match hidden_dim after concatenation\n",
    "        self.projection_layer = nn.Linear(hidden_dim * 3, hidden_dim)\n",
    "\n",
    "    def forward(self, x_list):\n",
    "        combined_hidden = torch.stack([x.mean(dim=1) for x in x_list], dim=1).mean(dim=1)\n",
    "        tanh_hidden = torch.tanh(self.fc(combined_hidden))\n",
    "        attention_scores = self.final_fc(tanh_hidden).squeeze(-1)\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1).unsqueeze(-1)\n",
    "        context_vector = combined_hidden * attention_weights\n",
    "        repeated_context = self.residual_fc(context_vector).unsqueeze(1)\n",
    "        # Concatenation and projection to hidden_dim\n",
    "        enriched_context_list = [\n",
    "            self.projection_layer(torch.cat((x, repeated_context.repeat(1, x.size(1), 1), x * repeated_context), dim=-1))\n",
    "            for x in x_list\n",
    "        ]\n",
    "        return enriched_context_list\n",
    "\n",
    "\n",
    "class FATHOMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, window_size=32):\n",
    "        super(FATHOMModel, self).__init__()\n",
    "        self.task_attention = TaskSpecificAttention(input_dim)\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim * 3, hidden_dim, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, shared_context):\n",
    "        x = self.task_attention(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        enriched_context = torch.cat((x, shared_context, x * shared_context), dim=-1)\n",
    "        x, _ = self.lstm2(enriched_context)\n",
    "        x = torch.cat((x[:, -1, :], shared_context[:, -1, :]), dim=-1)\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "\n",
    "\n",
    "class MultiTaskFATHOM(nn.Module):\n",
    "    def __init__(self, num_tasks, input_dim, hidden_dim, output_dim, window_size=32):\n",
    "        super(MultiTaskFATHOM, self).__init__()\n",
    "        self.shared_global_attention = SharedGlobalTemporalAttention(hidden_dim)\n",
    "        self.tasks = nn.ModuleList([\n",
    "            FATHOMModel(input_dim, hidden_dim, output_dim, window_size) for _ in range(num_tasks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # n sites, n tensors: [batch_size, window_size, input_dim]\n",
    "        # print(len(inputs))\n",
    "        assert len(inputs) == len(self.tasks), (\n",
    "            f\"Mismatch: Received {len(inputs)} inputs but expected {len(self.tasks)} tasks.\"\n",
    "        )\n",
    "        first_stage_outputs = []\n",
    "        for task_model, x in zip(self.tasks, inputs):\n",
    "            x, _ = task_model.lstm1(task_model.task_attention(x))\n",
    "            first_stage_outputs.append(x)\n",
    "\n",
    "        shared_contexts = self.shared_global_attention(first_stage_outputs)\n",
    "        outputs = []\n",
    "        for i, (task_model, x, shared_context) in enumerate(zip(self.tasks, inputs, shared_contexts)):\n",
    "            preds = task_model(x, shared_context)\n",
    "            outputs.append(preds)\n",
    "            # print(f\"Task {i + 1}: Output shape {preds.shape}\")\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# ------------------ DATA LOADER ------------------\n",
    "\n",
    "def df_to_X_y(df, features, target, window_size=32, horizon=1):\n",
    "    if target not in features:\n",
    "        features = [target] + features\n",
    "\n",
    "    data = df[features].to_numpy()\n",
    "    target_data = df[target].to_numpy()\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - horizon + 1):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(target_data[i + window_size: i + window_size + horizon])\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def load_and_preprocess_site_data(site_path, features, target, window_size=32, horizon=1, min_date=None, max_date=None, batch_size=16, device='cpu'):\n",
    "    df = pd.read_csv(site_path)\n",
    "\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        if min_date:\n",
    "            min_date = dateutil.parser.parse(min_date) if isinstance(min_date, str) else min_date\n",
    "            df = df[df['date'] >= min_date]\n",
    "        if max_date:\n",
    "            max_date = dateutil.parser.parse(max_date) if isinstance(max_date, str) else max_date\n",
    "            df = df[df['date'] <= max_date]\n",
    "        df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "    if target not in features:\n",
    "        features = [target] + features\n",
    "\n",
    "    all_columns = features\n",
    "    if not all(col in df.columns for col in all_columns):\n",
    "        missing = [col for col in all_columns if col not in df.columns]\n",
    "        raise ValueError(f\"Missing columns in dataset: {missing}\")\n",
    "\n",
    "    train_size = int(0.8 * len(df))\n",
    "    train_df = df.iloc[:train_size]\n",
    "    test_df = df.iloc[train_size:]\n",
    "\n",
    "    val_size = int(0.2 * len(train_df))\n",
    "    train_df, val_df = train_df.iloc[:-val_size], train_df.iloc[-val_size:]\n",
    "\n",
    "    print(f\"Train size: {len(train_df)} | Validation size: {len(val_df)} | Test size: {len(test_df)}\")\n",
    "\n",
    "    train_mean, train_std = train_df[all_columns].mean(), train_df[all_columns].std()\n",
    "    train_df[all_columns] = (train_df[all_columns] - train_mean) / (train_std + 1e-8)\n",
    "    val_df[all_columns] = (val_df[all_columns] - train_mean) / (train_std + 1e-8)\n",
    "    test_df[all_columns] = (test_df[all_columns] - train_mean) / (train_std + 1e-8)\n",
    "    \n",
    "    # scaler = MinMaxScaler()\n",
    "    # train_df[all_columns] = scaler.fit_transform(train_df[all_columns])\n",
    "    # val_df[all_columns] = scaler.transform(val_df[all_columns])\n",
    "    # test_df[all_columns] = scaler.transform(test_df[all_columns])\n",
    "\n",
    "    X_train, y_train = df_to_X_y(train_df, features, target, window_size, horizon)\n",
    "    X_val, y_val = df_to_X_y(val_df, features, target, window_size, horizon)\n",
    "    X_test, y_test = df_to_X_y(test_df, features, target, window_size, horizon)\n",
    "\n",
    "    train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32).to(device), torch.tensor(y_train, dtype=torch.float32).to(device))\n",
    "    val_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32).to(device), torch.tensor(y_val, dtype=torch.float32).to(device))\n",
    "    test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32).to(device), torch.tensor(y_test, dtype=torch.float32).to(device))\n",
    "\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size, drop_last=True)\n",
    "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# ------------------ TRAINING & EVALUATION ------------------\n",
    "\n",
    "def train_fathom_model(site_loaders, input_dim, hidden_dim, output_dim, num_epochs, window_size ,device):\n",
    "    \n",
    "    num_tasks = len(site_loaders)\n",
    "    \n",
    "    model = MultiTaskFATHOM(num_tasks, input_dim, hidden_dim, output_dim, window_size).to(\"cpu\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Unpack loaders for each task\n",
    "    train_loaders = [loader_tuple[0] for loader_tuple in site_loaders]\n",
    "    val_loaders = [loader_tuple[1] for loader_tuple in site_loaders]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        # Iterate over batches from all tasks simultaneously\n",
    "        for batches in zip(*train_loaders):\n",
    "            # Each batch in batches is a tuple (X, y) for a given task\n",
    "            Xs = [batch[0].to(device) for batch in batches]\n",
    "            ys = [batch[1].to(device) for batch in batches]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # Pass the list of task batches to the model\n",
    "            preds_list = model(Xs)  # expects a list of tensors, one per task\n",
    "            \n",
    "            # Compute losses for each task and sum them\n",
    "            losses = [\n",
    "                criterion(pred, y.view(y.size(0), -1))\n",
    "                for pred, y in zip(preds_list, ys)\n",
    "            ]\n",
    "            total_loss = sum(losses)\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(total_loss.item())\n",
    "        \n",
    "        # Validation phase (similarly, iterate over all task validation loaders)\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batches in zip(*val_loaders):\n",
    "                Xs = [batch[0].to(device) for batch in batches]\n",
    "                ys = [batch[1].to(device) for batch in batches]\n",
    "                preds_list = model(Xs)\n",
    "                losses = [\n",
    "                    criterion(pred, y.view(y.size(0), -1)).item()\n",
    "                    for pred, y in zip(preds_list, ys)\n",
    "                ]\n",
    "                # Average loss over tasks for this batch\n",
    "                val_losses.append(sum(losses) / num_tasks)\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {np.mean(train_losses):.4f} | Validation Loss: {np.mean(val_losses):.4f}\")\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_fathom_model(model, site_loaders, device='cpu'):\n",
    "    model.eval()\n",
    "    # Prepare test loaders from site_loaders\n",
    "    test_loaders = [loader_tuple[2] for loader_tuple in site_loaders]\n",
    "    task_preds, task_targets = [[] for _ in range(len(test_loaders))], [[] for _ in range(len(test_loaders))]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batches in zip(*test_loaders):\n",
    "            Xs = [batch[0].to(device) for batch in batches]\n",
    "            ys = [batch[1].to(device) for batch in batches]\n",
    "            preds_list = model(Xs)\n",
    "            for i, (pred, y) in enumerate(zip(preds_list, ys)):\n",
    "                task_preds[i].append(pred.cpu().numpy())\n",
    "                task_targets[i].append(y.cpu().numpy())\n",
    "    \n",
    "    # Compute MAE for each task\n",
    "    mae_scores = []\n",
    "    for preds, targets in zip(task_preds, task_targets):\n",
    "        preds_concat = np.concatenate(preds)\n",
    "        targets_concat = np.concatenate(targets)\n",
    "        mae_scores.append(mean_absolute_error(targets_concat, preds_concat))\n",
    "    \n",
    "    print(\"Evaluation complete.\")\n",
    "    return mae_scores\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions_vs_ground_truth(model, site_loaders, device='cpu', window_size=32, stride=16):\n",
    "    \"\"\"\n",
    "    Plots the model predictions vs. ground truth for each task using the test DataLoader.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained multi-task model.\n",
    "        site_loaders: List of tuples (train_loader, val_loader, test_loader) for each site.\n",
    "        device: \"cpu\" or \"cuda\".\n",
    "        window_size: Sliding window size used during training.\n",
    "        stride: Plot every 'stride'-th point to reduce clutter.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Extract test loaders from each (train, val, test) tuple\n",
    "    test_loaders = [loaders[2] for loaders in site_loaders]\n",
    "\n",
    "    # Collect predictions and ground truth from each task\n",
    "    all_preds = [[] for _ in range(len(test_loaders))]\n",
    "    all_truth = [[] for _ in range(len(test_loaders))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Zip all test loaders to get one batch per task at each iteration\n",
    "        for batches in zip(*test_loaders):\n",
    "            # For each task, extract inputs and targets\n",
    "            Xs = [batch[0].to(device) for batch in batches]\n",
    "            ys = [batch[1].to(device) for batch in batches]\n",
    "\n",
    "            # Forward pass for all tasks\n",
    "            preds_list = model(Xs)\n",
    "\n",
    "            # Accumulate predictions and ground truths\n",
    "            for i in range(len(test_loaders)):\n",
    "                all_preds[i].append(preds_list[i].cpu().numpy())\n",
    "                all_truth[i].append(ys[i].cpu().numpy())\n",
    "\n",
    "    # Now plot for each task\n",
    "    for i in range(len(test_loaders)):\n",
    "        # Concatenate along batch dimension and flatten\n",
    "        preds_i = np.concatenate(all_preds[i], axis=0).flatten()\n",
    "        truth_i = np.concatenate(all_truth[i], axis=0).flatten()\n",
    "\n",
    "        # Truncate to the same length, just in case\n",
    "        min_len = min(len(preds_i), len(truth_i))\n",
    "        preds_i = preds_i[:min_len]\n",
    "        truth_i = truth_i[:min_len]\n",
    "\n",
    "        # Build x-axes\n",
    "        # Ground truth covers indices [0, 1, 2, ..., min_len-1]\n",
    "        # Predictions are typically \"window_size\" steps ahead\n",
    "        time_axis = np.arange(min_len)\n",
    "        pred_axis = time_axis + window_size  # shift by window_size\n",
    "\n",
    "        # Downsample for plotting clarity (optional)\n",
    "        time_axis_plot = time_axis[::stride]\n",
    "        truth_plot = truth_i[::stride]\n",
    "        pred_axis_plot = pred_axis[::stride]\n",
    "        preds_plot = preds_i[::stride]\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(time_axis_plot, truth_plot, label=\"Ground Truth\", linewidth=1)\n",
    "        plt.plot(pred_axis_plot, preds_plot, label=\"Predictions\", linewidth=1, linestyle='--')\n",
    "        plt.title(f\"Task {i+1} Predictions vs Ground Truth\")\n",
    "        plt.xlabel(\"Sample Index\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # base_path = '../processed_ds/air_quality_cluster'\n",
    "#     # features = ['PM2.5', 'OT', 'PM10', 'NO2']\n",
    "#     # target = 'PM2.5'\n",
    "#     # min_date = \"2014-09-01\"\n",
    "#     # max_date =  \"2014-11-12 19:00\"\n",
    "    \n",
    "#     # ds = 'Solar_feb_22'\n",
    "#     # features =  ['loc-1', 'loc-2', 'loc-3', 'loc-4']\n",
    "#     # target = 'loc-1'\n",
    "#     # base_path =  \"../processed_ds/solar/\"\n",
    "#     # min_date = \"2006-09-01\"\n",
    "#     # max_date= \"2006-09-08 4:50\"\n",
    "    \n",
    "#     ds = 'Crypto_feb_22'\n",
    "#     features =  ['Open', 'High', 'Low', 'OT', 'Volume']\n",
    "#     target = 'OT'\n",
    "#     base_path =  \"../processed_ds/crypto-data/\"\n",
    "#     min_date = \"2018-04-01\"\n",
    "#     max_date= \"2018-06-15\"\n",
    "    \n",
    "#     site_paths = [\n",
    "#         os.path.join(root, file)\n",
    "#         for root, dirs, files in os.walk(base_path)\n",
    "#         if root != base_path  # Exclude files in the base directory\n",
    "#         for file in files\n",
    "#         if file.endswith(\".csv\")\n",
    "#     ]\n",
    "\n",
    "#     total_sites = len(site_paths)\n",
    "    \n",
    "#     num_tasks = total_sites\n",
    "#     batch_size, window_size, input_dim, hidden_dim, output_dim = 32, 32, len(features), 64, 16\n",
    "\n",
    "#     # model = MultiTaskFATHOM(num_tasks, input_dim, hidden_dim, output_dim, window_size).to(\"cpu\")\n",
    "#     # optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "#     # criterion = nn.MSELoss()\n",
    "\n",
    "#     site_loaders = [load_and_preprocess_site_data(site_path, \n",
    "#                                                   features, \n",
    "#                                                   target, \n",
    "#                                                   window_size, \n",
    "#                                                   horizon=output_dim, \n",
    "#                                                   batch_size=batch_size, \n",
    "#                                                   min_date=min_date,\n",
    "#                                                   max_date=max_date) for site_path in site_paths]\n",
    "\n",
    "#     model = train_fathom_model(site_loaders, input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_epochs=5, window_size=window_size, device='')\n",
    "#     mae_scores = evaluate_fathom_model(model, site_loaders, device=\"cpu\")\n",
    "#     print(f\"MAE per task: {mae_scores}\")\n",
    "#     # Plot the predictions vs ground truth for each task\n",
    "#     # plot_predictions_vs_ground_truth(model, site_loaders, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Task Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ------------------ BASELINE SINGLE-TASK MODEL ------------------\n",
    "\n",
    "class SingleTaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Baseline model with NO information sharing between tasks. Each task runs independently.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, window_size=32):\n",
    "        super(SingleTaskModel, self).__init__()\n",
    "        self.task_attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_weights = self.task_attention(x)\n",
    "        x = x * attention_weights  # Element-wise feature weighting\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = x[:, -1, :]  # Last time step output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "# ------------------ TRAINING & EVALUATION FOR BASELINE ------------------\n",
    "\n",
    "def train_STL_model(site_loaders, input_dim, hidden_dim, output_dim, num_epochs=5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains independent models per site (NO information sharing between tasks).\n",
    "    \"\"\"\n",
    "    num_tasks = len(site_loaders)\n",
    "    models = [SingleTaskModel(input_dim, hidden_dim, output_dim).to(device) for _ in range(num_tasks)]\n",
    "    optimizers = [torch.optim.Adam(model.parameters(), lr=0.001) for model in models]\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for task_id, (train_loader, val_loader, _) in enumerate(site_loaders):\n",
    "            models[task_id].train()\n",
    "            train_losses = []\n",
    "\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizers[task_id].zero_grad()\n",
    "                preds = models[task_id](X)\n",
    "                loss = criterion(preds, y.view(y.size(0), -1))\n",
    "                loss.backward()\n",
    "                optimizers[task_id].step()\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs} | Task {task_id + 1} | Train Loss: {np.mean(train_losses):.4f}\")\n",
    "\n",
    "    print(\"Baseline training complete.\")\n",
    "    return models\n",
    "\n",
    "\n",
    "def evaluate_stl_model(models, site_loaders, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates independent models per site and computes MAE.\n",
    "    \"\"\"\n",
    "    mae_scores = []\n",
    "\n",
    "    for task_id, (_, _, test_loader) in enumerate(site_loaders):\n",
    "        models[task_id].eval()\n",
    "        all_preds, all_targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                preds = models[task_id](X)\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_targets.append(y.cpu().numpy())\n",
    "\n",
    "        preds_concat = np.concatenate(all_preds, axis=0)\n",
    "        targets_concat = np.concatenate(all_targets, axis=0)\n",
    "        mae = mean_absolute_error(targets_concat, preds_concat)\n",
    "        mae_scores.append(mae)\n",
    "        print(f\"Task {task_id + 1} - Baseline MAE: {mae:.4f}\")\n",
    "\n",
    "    print(\"Baseline evaluation complete.\")\n",
    "    return mae_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 🌟 DATASET: Solar ====================\n",
      "\n",
      "==================== ⏳ HORIZON: 1 ====================\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Epoch 1/5 | Task 1 | Train Loss: 0.7238\n",
      "Epoch 1/5 | Task 2 | Train Loss: 0.6652\n",
      "Epoch 1/5 | Task 3 | Train Loss: 0.6702\n",
      "Epoch 1/5 | Task 4 | Train Loss: 0.6366\n",
      "Epoch 1/5 | Task 5 | Train Loss: 0.6782\n",
      "Epoch 1/5 | Task 6 | Train Loss: 0.7821\n",
      "Epoch 2/5 | Task 1 | Train Loss: 0.2324\n",
      "Epoch 2/5 | Task 2 | Train Loss: 0.2634\n",
      "Epoch 2/5 | Task 3 | Train Loss: 0.1676\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m\n\u001b[1;32m     56\u001b[0m site_loaders \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     57\u001b[0m     load_and_preprocess_site_data(\n\u001b[1;32m     58\u001b[0m         site_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     ) \u001b[38;5;28;01mfor\u001b[39;00m site_path \u001b[38;5;129;01min\u001b[39;00m site_paths\n\u001b[1;32m     67\u001b[0m ]\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Train and evaluate baseline models for comparison\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m baseline_stl_models \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_STL_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m baseline_stl_mae \u001b[38;5;241m=\u001b[39m evaluate_stl_model(baseline_stl_models, site_loaders, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Completed STL : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Horizon: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhorizon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Baseline MAE per task: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_stl_mae\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 58\u001b[0m, in \u001b[0;36mtrain_STL_model\u001b[0;34m(site_loaders, input_dim, hidden_dim, output_dim, num_epochs, device)\u001b[0m\n\u001b[1;32m     56\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     57\u001b[0m optimizers[task_id]\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 58\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, y\u001b[38;5;241m.\u001b[39mview(y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     60\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/Arnob/centralized-baseline/centralized/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Arnob/centralized-baseline/centralized/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mSingleTaskModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m attention_weights  \u001b[38;5;66;03m# Element-wise feature weighting\u001b[39;00m\n\u001b[1;32m     32\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm1(x)\n\u001b[0;32m---> 33\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# Last time step output\u001b[39;00m\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[0;32m~/Documents/Arnob/centralized-baseline/centralized/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Arnob/centralized-baseline/centralized/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Arnob/centralized-baseline/centralized/lib/python3.8/site-packages/torch/nn/modules/rnn.py:917\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "datasets = [\n",
    "    {\n",
    "        'ds': 'Solar',\n",
    "        'features': ['loc-1', 'loc-2', 'loc-3', 'loc-4'],\n",
    "        'target': 'loc-1',\n",
    "        'base_path': \"../processed_ds/solar/\",\n",
    "        'min_date': \"2006-09-01\",\n",
    "        'max_date': \"2006-09-08 4:50\"\n",
    "    },\n",
    "    {\n",
    "        'ds': 'Air Quality',\n",
    "        'features': ['PM2.5', 'OT', 'PM10', 'NO2'],\n",
    "        'target': 'PM2.5',\n",
    "        'base_path': '../processed_ds/air_quality_cluster',\n",
    "        'min_date': \"2014-09-01\",\n",
    "        'max_date': \"2014-11-12 19:00\"\n",
    "    },\n",
    "    {\n",
    "        'ds': 'Crypto',\n",
    "        'features': ['Open', 'High', 'Low', 'OT', 'Volume'],\n",
    "        'target': 'OT',\n",
    "        'base_path': \"../processed_ds/crypto-data/\",\n",
    "        'min_date': \"2018-04-01\",\n",
    "        'max_date': \"2018-06-15\"\n",
    "    },\n",
    "    # {\n",
    "    #     'ds': 'Sales',\n",
    "    #     'features': ['OT', 'customers', 'open', 'promo', 'holiday'],\n",
    "    #     'target': 'OT',\n",
    "    #     'base_path': \"../processed_ds/stores_data/\",\n",
    "    #     'min_date': \"2013-01-16\",\n",
    "    #     'max_date': \"2015-07-31\"\n",
    "    # }\n",
    "]\n",
    "\n",
    "horizons = [1, 2, 4, 8, 16]\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"\\n==================== 🌟 DATASET: {dataset['ds']} ====================\")\n",
    "    for horizon in horizons:\n",
    "        print(f\"\\n==================== ⏳ HORIZON: {horizon} ====================\")\n",
    "        \n",
    "        site_paths = [\n",
    "            os.path.join(root, file)\n",
    "            for root, dirs, files in os.walk(dataset['base_path'])\n",
    "            if root != dataset['base_path']\n",
    "            for file in files\n",
    "            if file.endswith(\".csv\")\n",
    "        ]\n",
    "\n",
    "        total_sites = len(site_paths)\n",
    "        num_tasks = total_sites\n",
    "        batch_size, window_size, input_dim, hidden_dim, output_dim = 32, 32, len(dataset['features']), 64, horizon\n",
    "\n",
    "        site_loaders = [\n",
    "            load_and_preprocess_site_data(\n",
    "                site_path,\n",
    "                dataset['features'],\n",
    "                dataset['target'],\n",
    "                window_size,\n",
    "                horizon=output_dim,\n",
    "                batch_size=batch_size,\n",
    "                min_date=dataset['min_date'],\n",
    "                max_date=dataset['max_date']\n",
    "            ) for site_path in site_paths\n",
    "        ]\n",
    "\n",
    "        # Train and evaluate baseline models for comparison\n",
    "        baseline_stl_models = train_STL_model(site_loaders, input_dim, hidden_dim, output_dim, num_epochs=5, device='cpu')\n",
    "        baseline_stl_mae = evaluate_stl_model(baseline_stl_models, site_loaders, device='cpu')\n",
    "\n",
    "        print(f\"✅ Completed STL : {dataset['ds']} | Horizon: {horizon} | Baseline MAE per task: {baseline_stl_mae}\")\n",
    "        store_results(dataset_name=dataset['ds'],\n",
    "                      horizons=[1,2,4,8,16],\n",
    "                      horizon_value=horizon,\n",
    "                      experiment_type='independent',\n",
    "                      mae_result=baseline_stl_mae,\n",
    "                      backbone='deep_lstm',\n",
    "                      file_path='deep_forecasting_results.json'\n",
    "                    )\n",
    "        # Train MTL\n",
    "        mtl_model = train_fathom_model(site_loaders, input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_epochs=5, window_size=window_size, device='cpu')\n",
    "        mtl_scores = evaluate_fathom_model(mtl_model, site_loaders, device=\"cpu\")\n",
    "        print(f\"✅ Completed MTL : {dataset['ds']} | Horizon: {horizon} | MTL MAE per task: {mtl_scores}\")\n",
    "        store_results(dataset_name=dataset['ds'],\n",
    "                      horizons=[1,2,4,8,16],\n",
    "                      horizon_value=horizon,\n",
    "                      experiment_type='mtl',\n",
    "                      mae_result=mtl_scores,\n",
    "                      backbone='deep_lstm',\n",
    "                      file_path='deep_forecasting_results.json'\n",
    "                    )\n",
    "        \n",
    "print(\"\\n🏆 All experiments completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centralized",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
