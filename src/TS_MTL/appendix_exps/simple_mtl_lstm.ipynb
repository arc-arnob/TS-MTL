{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_existing_results(file_path=\"forecasting_results.json\"):\n",
    "    \"\"\"\n",
    "    Load existing results from a JSON file.\n",
    "    Returns an empty dictionary if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "\n",
    "def save_results_to_json(data, file_path=\"forecasting_results.json\"):\n",
    "    \"\"\"\n",
    "    Save the results dictionary to a JSON file, handling NumPy data types.\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle NumPy data types (recursive conversion)\n",
    "    def convert_numpy(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: convert_numpy(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_numpy(i) for i in obj]\n",
    "        elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()  # Convert arrays to lists\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    # Convert data and save to JSON\n",
    "    data = convert_numpy(data)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"✅ Results saved to {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def store_results(dataset_name, horizons, horizon_value, experiment_type, backbone, mae_result, file_path=\"forecasting_results.json\"):\n",
    "    \"\"\"\n",
    "    Store MAE results for a given experiment type (stl_mae, mtl_mae, global_mae) per horizon.\n",
    "\n",
    "    Args:\n",
    "    - dataset_name (str): Name of the dataset (e.g., 'Solar', 'Air Quality').\n",
    "    - horizons (list): List of horizon values (e.g., [1, 2, 4, 8, 16]).\n",
    "    - horizon_value (int): The horizon corresponding to the mae_result provided.\n",
    "    - experiment_type (str): One of ['stl_mae', 'mtl_mae', 'global_mae'].\n",
    "    - backbone (str): Model backbone name (e.g., 'Deep_LSTM', 'simple_transformer').\n",
    "    - mae_result (list): MAE values for the current horizon (list of floats).\n",
    "    - file_path (str): JSON file to store the results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Load existing results\n",
    "    results_dict = load_existing_results(file_path)\n",
    "\n",
    "    # Create dataset entry if it doesn't exist\n",
    "    dataset_key = f\"{dataset_name}_{backbone}\"\n",
    "    if dataset_key not in results_dict:\n",
    "        results_dict[dataset_key] = {\n",
    "            \"horizons\": horizons,\n",
    "            \"mtl\": [[] for _ in horizons],\n",
    "            \"global\": [[] for _ in horizons],\n",
    "            \"independent\": [[] for _ in horizons]\n",
    "        }\n",
    "\n",
    "    # Find index for the given horizon\n",
    "    try:\n",
    "        horizon_index = horizons.index(horizon_value)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"⚠️ Horizon value {horizon_value} not found in {horizons}.\")\n",
    "\n",
    "    # Append the mae_result to the correct horizon\n",
    "    results_dict[dataset_key][experiment_type][horizon_index].extend(mae_result)\n",
    "\n",
    "    # Save updated results\n",
    "    save_results_to_json(results_dict, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def df_to_X_y(df, features, target, window_size=32, horizon=1):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame into supervised learning format for multi-step time series forecasting.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing time series data.\n",
    "    - features (list): List of columns to use as features.\n",
    "    - target (str): The target column to predict.\n",
    "    - window_size (int): Past window size.\n",
    "    - horizon (int): Number of future steps.\n",
    "\n",
    "    Returns:\n",
    "    - X (np.array): Features (num_samples, window_size, num_features).\n",
    "    - y (np.array): Targets (num_samples, horizon).\n",
    "    \"\"\"\n",
    "    # Ensure target is in features\n",
    "    if target not in features:\n",
    "        features = [target] + features\n",
    "\n",
    "    data = df[features].to_numpy()  # Features including target's history\n",
    "    target_data = df[target].to_numpy()  # Target series\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - horizon + 1):\n",
    "        # Past window_size feature values (including target)\n",
    "        X.append(data[i:i + window_size])\n",
    "\n",
    "        # Multi-step target: a sequence of future steps\n",
    "        y.append(target_data[i + window_size : i + window_size + horizon])\n",
    "\n",
    "    return np.array(X), np.array(y)  # y shape: (num_samples, horizon)\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Data Loader Function (Target included in features) ----------\n",
    "def load_and_preprocess_site_data(site_path, features, target, window_size=32, horizon=1, min_date=None, max_date=None, batch_size=16, device='cpu'):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses time series data for a given site with specified features and target,\n",
    "    ensuring the target column's historical values are included in the features.\n",
    "    \n",
    "    Args:\n",
    "    - site_path (str): Path to the CSV file.\n",
    "    - features (list): List of feature columns to use.\n",
    "    - target (str): Target column name.\n",
    "    - window_size (int): Past window size.\n",
    "    - horizon (int): Forecast horizon.\n",
    "    - min_date, max_date (str or datetime): Optional date filtering.\n",
    "    - batch_size (int): Batch size for DataLoader.\n",
    "    - device (str): 'cpu' or 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "    - train_loader, val_loader, test_loader: PyTorch DataLoaders.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(site_path)\n",
    "\n",
    "    # Convert date column to datetime if exists\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        if min_date:\n",
    "            min_date = dateutil.parser.parse(min_date) if isinstance(min_date, str) else min_date\n",
    "            df = df[df['date'] >= min_date]\n",
    "        if max_date:\n",
    "            max_date = dateutil.parser.parse(max_date) if isinstance(max_date, str) else max_date\n",
    "            df = df[df['date'] <= max_date]\n",
    "        df.drop(columns=['date'], inplace=True)\n",
    "    # Ensure target is included in the feature set\n",
    "    if target not in features:\n",
    "        features = [target] + features\n",
    "\n",
    "    # Check for missing columns\n",
    "    all_columns = features\n",
    "    if not all(col in df.columns for col in all_columns):\n",
    "        missing = [col for col in all_columns if col not in df.columns]\n",
    "        raise ValueError(f\"Missing columns in dataset: {missing}\")\n",
    "\n",
    "    # Split data: 80% Train/Val, 20% Test\n",
    "    train_size = int(0.8 * len(df))\n",
    "    train_df = df.iloc[:train_size]\n",
    "    test_df = df.iloc[train_size:]\n",
    "\n",
    "    # 16% validation from train set\n",
    "    val_size = int(0.2 * len(train_df))\n",
    "    train_df, val_df = train_df.iloc[:-val_size], train_df.iloc[-val_size:]\n",
    "\n",
    "    print(f\"Train size: {len(train_df)} | Validation size: {len(val_df)} | Test size: {len(test_df)}\")\n",
    "\n",
    "    # # Standardization (using training stats)\n",
    "    train_mean, train_std = train_df[all_columns].mean(), train_df[all_columns].std()\n",
    "    train_df[all_columns] = (train_df[all_columns] - train_mean) / (train_std + 1e-8)\n",
    "    val_df[all_columns] = (val_df[all_columns] - train_mean) / (train_std + 1e-8)\n",
    "    test_df[all_columns] = (test_df[all_columns] - train_mean) / (train_std + 1e-8)\n",
    "    \n",
    "    # ✅ **Min-Max Scaling** (fitted on train only)\n",
    "    # scaler = MinMaxScaler()\n",
    "    # train_df[all_columns] = scaler.fit_transform(train_df[all_columns])\n",
    "    # val_df[all_columns] = scaler.transform(val_df[all_columns])\n",
    "    # test_df[all_columns] = scaler.transform(test_df[all_columns])\n",
    "\n",
    "    # Generate sequences\n",
    "    X_train, y_train = df_to_X_y(train_df, features, target, window_size, horizon)\n",
    "    X_val, y_val = df_to_X_y(val_df, features, target, window_size, horizon)\n",
    "    X_test, y_test = df_to_X_y(test_df, features, target, window_size, horizon)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32).to(device), torch.tensor(y_train, dtype=torch.float32).to(device))\n",
    "    val_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32).to(device), torch.tensor(y_val, dtype=torch.float32).to(device))\n",
    "    test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32).to(device), torch.tensor(y_test, dtype=torch.float32).to(device))\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size, drop_last=True)\n",
    "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader #,scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMultiTaskLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_tasks, num_layers=2):\n",
    "        super(SimpleMultiTaskLSTM, self).__init__()\n",
    "        self.shared_lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.task_heads = nn.ModuleList([nn.Linear(hidden_dim, output_dim) for _ in range(num_tasks)])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "        for i, x in enumerate(inputs):\n",
    "            x, _ = self.shared_lstm(x)  # Shared representation\n",
    "            x = x[:, -1, :]  # Last time step output\n",
    "            outputs.append(self.task_heads[i](x))  # Task-specific prediction\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ TRAINING & EVALUATION FOR SIMPLE MTL ------------------\n",
    "\n",
    "def train_simple_mtl_model(site_loaders, input_dim, hidden_dim, output_dim, num_tasks, num_epochs=5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains the SimpleMultiTaskLSTM model across multiple site datasets.\n",
    "    \"\"\"\n",
    "    model = SimpleMultiTaskLSTM(input_dim, hidden_dim, output_dim, num_tasks).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "\n",
    "    # Unpack loaders for each task\n",
    "    train_loaders = [loader_tuple[0] for loader_tuple in site_loaders]\n",
    "    val_loaders = [loader_tuple[1] for loader_tuple in site_loaders]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        # Iterate over batches from all tasks simultaneously\n",
    "        for batches in zip(*train_loaders):\n",
    "            # Each batch in batches is a tuple (X, y) for a given task\n",
    "            Xs = [batch[0].to(device) for batch in batches]\n",
    "            ys = [batch[1].to(device) for batch in batches]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # Pass the list of task batches to the model\n",
    "            preds_list = model(Xs)  # expects a list of tensors, one per task\n",
    "            \n",
    "            # Compute losses for each task and sum them\n",
    "            losses = [\n",
    "                criterion(pred, y.view(y.size(0), -1))\n",
    "                for pred, y in zip(preds_list, ys)\n",
    "            ]\n",
    "            total_loss = sum(losses)\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(total_loss.item())\n",
    "        \n",
    "        # Validation phase (similarly, iterate over all task validation loaders)\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batches in zip(*val_loaders):\n",
    "                Xs = [batch[0].to(device) for batch in batches]\n",
    "                ys = [batch[1].to(device) for batch in batches]\n",
    "                preds_list = model(Xs)\n",
    "                losses = [\n",
    "                    criterion(pred, y.view(y.size(0), -1)).item()\n",
    "                    for pred, y in zip(preds_list, ys)\n",
    "                ]\n",
    "                # Average loss over tasks for this batch\n",
    "                val_losses.append(sum(losses) / num_tasks)\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {np.mean(train_losses):.4f} | Validation Loss: {np.mean(val_losses):.4f}\")\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_simple_mtl_model(model, site_loaders, device='cpu', ds=\"NK\", horizon_val = 1):\n",
    "    \"\"\"\n",
    "    Evaluates the SimpleMultiTaskLSTM model on the test set for all sites and computes MAE for each site.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Prepare test loaders from site_loaders\n",
    "    test_loaders = [loader_tuple[2] for loader_tuple in site_loaders]\n",
    "    task_preds, task_targets = [[] for _ in range(len(test_loaders))], [[] for _ in range(len(test_loaders))]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batches in zip(*test_loaders):\n",
    "            Xs = [batch[0].to(device) for batch in batches]\n",
    "            ys = [batch[1].to(device) for batch in batches]\n",
    "            preds_list = model(Xs)\n",
    "            for i, (pred, y) in enumerate(zip(preds_list, ys)):\n",
    "                task_preds[i].append(pred.cpu().numpy())\n",
    "                task_targets[i].append(y.cpu().numpy())\n",
    "    \n",
    "    # Compute MAE for each task\n",
    "    mae_scores = []\n",
    "    for preds, targets in zip(task_preds, task_targets):\n",
    "        preds_concat = np.concatenate(preds)\n",
    "        targets_concat = np.concatenate(targets)\n",
    "        mae_scores.append(mean_absolute_error(targets_concat, preds_concat))\n",
    "    \n",
    "    print(\"Simple Transformer MTL evaluation complete.\")\n",
    "    # Append results to output.txt\n",
    "    with open(\"output_test.txt\", \"a\") as f:\n",
    "        f.write(f\"\\n==================== Simple LSTM MTL MODEL RESULTS {ds} ====================\\n\")\n",
    "        f.write(f\"MAE per task: {mae_scores}\\n\")\n",
    "    store_results(\n",
    "        dataset_name=ds,\n",
    "        horizons=[1,2,4,8,16],\n",
    "        horizon_value=horizon_val,\n",
    "        experiment_type='mtl',\n",
    "        mae_result=mae_scores,\n",
    "        backbone='simple_lstm'\n",
    "    )\n",
    "    print(\"Evaluation complete.\")\n",
    "    return mae_scores\n",
    "\n",
    "\n",
    "def plot_simple_mtl_predictions(model, site_loaders, device='cpu'):\n",
    "    \"\"\"\n",
    "    Plots predictions vs. ground truth for each site in the SimpleMultiTaskLSTM model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    for task_id, (_, _, test_loader) in enumerate(site_loaders):\n",
    "        all_preds, all_truths = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                preds = model([X])[task_id]\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_truths.append(y.cpu().numpy())\n",
    "\n",
    "        preds_concat = np.concatenate(all_preds, axis=0).flatten()\n",
    "        truths_concat = np.concatenate(all_truths, axis=0).flatten()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(truths_concat, label=\"Ground Truth\", linewidth=1)\n",
    "        plt.plot(preds_concat, label=\"Simple MTL Prediction\", linewidth=1, linestyle='--')\n",
    "        plt.title(f\"Simple MTL - Task {task_id + 1}: Predictions vs Ground Truth\")\n",
    "        plt.xlabel(\"Sample Index\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ TRAINING PIPELINE FOR SIMPLE MTL ------------------\n",
    "\n",
    "def run_simple_mtl_pipeline(datasets, horizons, device='cpu'):\n",
    "    \"\"\"\n",
    "    Runs the full training, evaluation, and plotting pipeline for the SimpleMultiTaskLSTM model.\n",
    "    \"\"\"\n",
    "    for dataset in datasets:\n",
    "        print(f\"\\n==================== 🌟 DATASET: {dataset['ds']} ====================\")\n",
    "        for horizon in horizons:\n",
    "            print(f\"\\n==================== ⏳ HORIZON: {horizon} ====================\")\n",
    "\n",
    "            site_paths = [\n",
    "                os.path.join(root, file)\n",
    "                for root, dirs, files in os.walk(dataset['base_path'])\n",
    "                if root != dataset['base_path']\n",
    "                for file in files\n",
    "                if file.endswith(\".csv\")\n",
    "            ]\n",
    "\n",
    "            total_sites = len(site_paths)\n",
    "            num_tasks = total_sites\n",
    "            batch_size, window_size, input_dim, hidden_dim, output_dim = 32, 32, len(dataset['features']), 64, horizon\n",
    "\n",
    "            site_loaders = [\n",
    "                load_and_preprocess_site_data(\n",
    "                    site_path,\n",
    "                    dataset['features'],\n",
    "                    dataset['target'],\n",
    "                    window_size,\n",
    "                    horizon=output_dim,\n",
    "                    batch_size=batch_size,\n",
    "                    min_date=dataset['min_date'],\n",
    "                    max_date=dataset['max_date']\n",
    "                ) for site_path in site_paths\n",
    "            ]\n",
    "\n",
    "            # Training Simple MTL model\n",
    "            simple_mtl_model = train_simple_mtl_model(site_loaders, input_dim, hidden_dim, output_dim, num_tasks, num_epochs=5, device=device)\n",
    "            # Evaluating Simple MTL model\n",
    "            simple_mtl_mae = evaluate_simple_mtl_model(simple_mtl_model, site_loaders, device=device, ds=dataset['ds'], horizon_val=horizon)\n",
    "            # Plotting predictions\n",
    "            # plot_simple_mtl_predictions(simple_mtl_model, site_loaders, device=device)\n",
    "\n",
    "            print(f\"✅ Completed: {dataset['ds']} | Horizon: {horizon} | Simple MTL MAE per task: {simple_mtl_mae}\")\n",
    "\n",
    "    print(\"\\n🏆 All Simple MTL experiments completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [1, 2, 4, 8, 16]\n",
    "\n",
    "# 🌐 Dataset Configurations\n",
    "datasets = [\n",
    "    {\n",
    "        'ds': 'Solar',\n",
    "        'features': ['loc-1', 'loc-2', 'loc-3', 'loc-4'],\n",
    "        'target': 'loc-1',\n",
    "        'base_path': \"../processed_ds/solar/\",\n",
    "        'min_date': \"2006-09-01\",\n",
    "        'max_date': \"2006-09-08 4:50\"\n",
    "    },\n",
    "    {\n",
    "        'ds': 'Air Quality',\n",
    "        'features': ['PM2.5', 'OT', 'PM10', 'NO2'],\n",
    "        'target': 'PM2.5',\n",
    "        'base_path': '../processed_ds/air_quality_cluster',\n",
    "        'min_date': \"2014-09-01\",\n",
    "        'max_date': \"2014-11-12 19:00\"\n",
    "    },\n",
    "    {\n",
    "        'ds': 'Crypto',\n",
    "        'features': ['Open', 'High', 'Low', 'OT', 'Volume'],\n",
    "        'target': 'OT',\n",
    "        'base_path': \"../processed_ds/crypto-data/\",\n",
    "        'min_date': \"2018-04-01\",\n",
    "        'max_date': \"2018-06-15\"\n",
    "    },\n",
    "    # {\n",
    "    #     'ds': 'Sales',\n",
    "    #     'features': ['OT', 'customers', 'open', 'promo', 'holiday'],\n",
    "    #     'target': 'OT',\n",
    "    #     'base_path': \"../processed_ds/stores_data/\",\n",
    "    #     'min_date': \"2013-01-16\",\n",
    "    #     'max_date': \"2015-07-31\"\n",
    "    # }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 🌟 DATASET: Solar ====================\n",
      "\n",
      "==================== ⏳ HORIZON: 1 ====================\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Epoch 1/5 | Train Loss: 3.2447 | Validation Loss: 0.2706\n",
      "Epoch 2/5 | Train Loss: 0.8593 | Validation Loss: 0.0967\n",
      "Epoch 3/5 | Train Loss: 0.5140 | Validation Loss: 0.0704\n",
      "Epoch 4/5 | Train Loss: 0.4260 | Validation Loss: 0.0629\n",
      "Epoch 5/5 | Train Loss: 0.3695 | Validation Loss: 0.0564\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Solar | Horizon: 1 | Simple MTL MAE per task: [0.12581824, 0.08264577, 0.14247364, 0.08760701, 0.12492793, 0.13448676]\n",
      "\n",
      "==================== ⏳ HORIZON: 2 ====================\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Epoch 1/5 | Train Loss: 3.6581 | Validation Loss: 0.2876\n",
      "Epoch 2/5 | Train Loss: 0.9028 | Validation Loss: 0.1018\n",
      "Epoch 3/5 | Train Loss: 0.5603 | Validation Loss: 0.0867\n",
      "Epoch 4/5 | Train Loss: 0.4949 | Validation Loss: 0.0784\n",
      "Epoch 5/5 | Train Loss: 0.4478 | Validation Loss: 0.0724\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Solar | Horizon: 2 | Simple MTL MAE per task: [0.15936966, 0.09548308, 0.16190194, 0.10569817, 0.15603319, 0.16606931]\n",
      "\n",
      "==================== ⏳ HORIZON: 4 ====================\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Epoch 1/5 | Train Loss: 3.6412 | Validation Loss: 0.2915\n",
      "Epoch 2/5 | Train Loss: 1.0221 | Validation Loss: 0.1155\n",
      "Epoch 3/5 | Train Loss: 0.7033 | Validation Loss: 0.1008\n",
      "Epoch 4/5 | Train Loss: 0.6249 | Validation Loss: 0.0929\n",
      "Epoch 5/5 | Train Loss: 0.5845 | Validation Loss: 0.0889\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Solar | Horizon: 4 | Simple MTL MAE per task: [0.14599034, 0.11195809, 0.1743815, 0.13539982, 0.1458778, 0.16048604]\n",
      "\n",
      "==================== ⏳ HORIZON: 8 ====================\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Epoch 1/5 | Train Loss: 3.9722 | Validation Loss: 0.3456\n",
      "Epoch 2/5 | Train Loss: 1.2279 | Validation Loss: 0.1542\n",
      "Epoch 3/5 | Train Loss: 0.9443 | Validation Loss: 0.1501\n",
      "Epoch 4/5 | Train Loss: 0.8553 | Validation Loss: 0.1369\n",
      "Epoch 5/5 | Train Loss: 0.8017 | Validation Loss: 0.1372\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Solar | Horizon: 8 | Simple MTL MAE per task: [0.21336241, 0.15910953, 0.2495395, 0.18709046, 0.1938642, 0.22303379]\n",
      "\n",
      "==================== ⏳ HORIZON: 16 ====================\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Train size: 1328 | Validation size: 332 | Test size: 415\n",
      "Epoch 1/5 | Train Loss: 4.2187 | Validation Loss: 0.4379\n",
      "Epoch 2/5 | Train Loss: 1.6850 | Validation Loss: 0.1936\n",
      "Epoch 3/5 | Train Loss: 1.3184 | Validation Loss: 0.1741\n",
      "Epoch 4/5 | Train Loss: 1.2170 | Validation Loss: 0.1725\n",
      "Epoch 5/5 | Train Loss: 1.1421 | Validation Loss: 0.1693\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Solar | Horizon: 16 | Simple MTL MAE per task: [0.2844771, 0.22175989, 0.3116007, 0.30289483, 0.27700645, 0.32347876]\n",
      "\n",
      "==================== 🌟 DATASET: Air Quality ====================\n",
      "\n",
      "==================== ⏳ HORIZON: 1 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Train Loss: 8.3348 | Validation Loss: 0.8257\n",
      "Epoch 2/5 | Train Loss: 2.2446 | Validation Loss: 0.3961\n",
      "Epoch 3/5 | Train Loss: 1.0788 | Validation Loss: 0.2340\n",
      "Epoch 4/5 | Train Loss: 0.7238 | Validation Loss: 0.1447\n",
      "Epoch 5/5 | Train Loss: 0.5836 | Validation Loss: 0.1172\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Air Quality | Horizon: 1 | Simple MTL MAE per task: [0.14435782, 0.1394985, 0.15148205, 0.14253081, 0.121990696, 0.15164447, 0.16489442, 0.124994226, 0.14793302, 0.14254439, 0.15951703, 0.14392672]\n",
      "\n",
      "==================== ⏳ HORIZON: 2 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Train Loss: 8.9230 | Validation Loss: 0.8448\n",
      "Epoch 2/5 | Train Loss: 2.6196 | Validation Loss: 0.4456\n",
      "Epoch 3/5 | Train Loss: 1.3668 | Validation Loss: 0.2970\n",
      "Epoch 4/5 | Train Loss: 1.0073 | Validation Loss: 0.2217\n",
      "Epoch 5/5 | Train Loss: 0.8395 | Validation Loss: 0.2060\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Air Quality | Horizon: 2 | Simple MTL MAE per task: [0.13881512, 0.16349128, 0.15459675, 0.13012037, 0.12934187, 0.16867164, 0.18698889, 0.13894716, 0.16987635, 0.17004567, 0.16772994, 0.15351595]\n",
      "\n",
      "==================== ⏳ HORIZON: 4 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Train Loss: 9.7625 | Validation Loss: 1.1354\n",
      "Epoch 2/5 | Train Loss: 3.2720 | Validation Loss: 0.6949\n",
      "Epoch 3/5 | Train Loss: 1.8078 | Validation Loss: 0.5180\n",
      "Epoch 4/5 | Train Loss: 1.4911 | Validation Loss: 0.4388\n",
      "Epoch 5/5 | Train Loss: 1.3104 | Validation Loss: 0.3987\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Air Quality | Horizon: 4 | Simple MTL MAE per task: [0.17814116, 0.22311012, 0.19753273, 0.17358163, 0.176642, 0.21199457, 0.2447629, 0.19429725, 0.22729221, 0.23227692, 0.23175494, 0.20744917]\n",
      "\n",
      "==================== ⏳ HORIZON: 8 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Train Loss: 9.9990 | Validation Loss: 1.1167\n",
      "Epoch 2/5 | Train Loss: 3.9824 | Validation Loss: 0.9144\n",
      "Epoch 3/5 | Train Loss: 2.6938 | Validation Loss: 1.0290\n",
      "Epoch 4/5 | Train Loss: 2.3280 | Validation Loss: 0.9282\n",
      "Epoch 5/5 | Train Loss: 2.1490 | Validation Loss: 0.8574\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Air Quality | Horizon: 8 | Simple MTL MAE per task: [0.2749341, 0.35332647, 0.26830775, 0.275131, 0.25819364, 0.2662837, 0.40183362, 0.3196088, 0.36456966, 0.3949978, 0.34375885, 0.29279613]\n",
      "\n",
      "==================== ⏳ HORIZON: 16 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Train Loss: 10.4830 | Validation Loss: 1.3065\n",
      "Epoch 2/5 | Train Loss: 5.0758 | Validation Loss: 1.5297\n",
      "Epoch 3/5 | Train Loss: 3.6303 | Validation Loss: 1.7117\n",
      "Epoch 4/5 | Train Loss: 3.2574 | Validation Loss: 1.7043\n",
      "Epoch 5/5 | Train Loss: 3.0291 | Validation Loss: 1.7094\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Air Quality | Horizon: 16 | Simple MTL MAE per task: [0.3466292, 0.4671467, 0.34932646, 0.4149852, 0.35339567, 0.33643067, 0.53579545, 0.4511404, 0.5000246, 0.62941706, 0.4555559, 0.35659683]\n",
      "\n",
      "==================== 🌟 DATASET: Crypto ====================\n",
      "\n",
      "==================== ⏳ HORIZON: 1 ====================\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 901 | Validation size: 225 | Test size: 282\n",
      "Epoch 1/5 | Train Loss: 2.5998 | Validation Loss: 0.1773\n",
      "Epoch 2/5 | Train Loss: 0.4811 | Validation Loss: 0.0305\n",
      "Epoch 3/5 | Train Loss: 0.2729 | Validation Loss: 0.0222\n",
      "Epoch 4/5 | Train Loss: 0.2338 | Validation Loss: 0.0181\n",
      "Epoch 5/5 | Train Loss: 0.2127 | Validation Loss: 0.0177\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Crypto | Horizon: 1 | Simple MTL MAE per task: [0.04543796, 0.05015287, 0.039898973, 0.5050056, 0.12762643]\n",
      "\n",
      "==================== ⏳ HORIZON: 2 ====================\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 901 | Validation size: 225 | Test size: 282\n",
      "Epoch 1/5 | Train Loss: 3.0195 | Validation Loss: 0.2719\n",
      "Epoch 2/5 | Train Loss: 0.5988 | Validation Loss: 0.0337\n",
      "Epoch 3/5 | Train Loss: 0.3026 | Validation Loss: 0.0274\n",
      "Epoch 4/5 | Train Loss: 0.2670 | Validation Loss: 0.0189\n",
      "Epoch 5/5 | Train Loss: 0.2497 | Validation Loss: 0.0156\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Crypto | Horizon: 2 | Simple MTL MAE per task: [0.058737136, 0.054776326, 0.04826103, 0.53744715, 0.03002288]\n",
      "\n",
      "==================== ⏳ HORIZON: 4 ====================\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 901 | Validation size: 225 | Test size: 282\n",
      "Epoch 1/5 | Train Loss: 3.1471 | Validation Loss: 0.1888\n",
      "Epoch 2/5 | Train Loss: 0.6660 | Validation Loss: 0.0326\n",
      "Epoch 3/5 | Train Loss: 0.3364 | Validation Loss: 0.0282\n",
      "Epoch 4/5 | Train Loss: 0.3071 | Validation Loss: 0.0223\n",
      "Epoch 5/5 | Train Loss: 0.2932 | Validation Loss: 0.0226\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Crypto | Horizon: 4 | Simple MTL MAE per task: [0.061258174, 0.06828167, 0.054629866, 0.6131447, 0.079243876]\n",
      "\n",
      "==================== ⏳ HORIZON: 8 ====================\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 901 | Validation size: 225 | Test size: 282\n",
      "Epoch 1/5 | Train Loss: 3.4817 | Validation Loss: 0.2530\n",
      "Epoch 2/5 | Train Loss: 0.9064 | Validation Loss: 0.0539\n",
      "Epoch 3/5 | Train Loss: 0.4318 | Validation Loss: 0.0399\n",
      "Epoch 4/5 | Train Loss: 0.3772 | Validation Loss: 0.0352\n",
      "Epoch 5/5 | Train Loss: 0.3843 | Validation Loss: 0.0348\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Crypto | Horizon: 8 | Simple MTL MAE per task: [0.07585777, 0.09891214, 0.07152193, 0.6741195, 0.13280547]\n",
      "\n",
      "==================== ⏳ HORIZON: 16 ====================\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 1152 | Validation size: 288 | Test size: 361\n",
      "Train size: 901 | Validation size: 225 | Test size: 282\n",
      "Epoch 1/5 | Train Loss: 3.7657 | Validation Loss: 0.3224\n",
      "Epoch 2/5 | Train Loss: 1.1058 | Validation Loss: 0.0750\n",
      "Epoch 3/5 | Train Loss: 0.6273 | Validation Loss: 0.0647\n",
      "Epoch 4/5 | Train Loss: 0.5728 | Validation Loss: 0.0619\n",
      "Epoch 5/5 | Train Loss: 0.5462 | Validation Loss: 0.0587\n",
      "Training complete.\n",
      "Simple Transformer MTL evaluation complete.\n",
      "✅ Results saved to forecasting_results.json\n",
      "Evaluation complete.\n",
      "✅ Completed: Crypto | Horizon: 16 | Simple MTL MAE per task: [0.1287702, 0.10997199, 0.09424111, 0.8007042, 0.22306742]\n",
      "\n",
      "🏆 All Simple MTL experiments completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "run_simple_mtl_pipeline(datasets=datasets, horizons=horizons, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ INDEPENDENT LSTM MODEL ------------------\n",
    "\n",
    "class IndependentLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_tasks, num_layers=1):\n",
    "        super(IndependentLSTM, self).__init__()\n",
    "        self.models = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True),\n",
    "                nn.Linear(hidden_dim, output_dim)\n",
    "            )\n",
    "            for _ in range(num_tasks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "        for model, x in zip(self.models, inputs):\n",
    "            lstm_out, _ = model[0](x)\n",
    "            x = lstm_out[:, -1, :]\n",
    "            outputs.append(model[1](x))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# ------------------ TRAINING & EVALUATION FOR INDEPENDENT LSTM ------------------\n",
    "\n",
    "def train_independent_lstm(site_loaders, input_dim, hidden_dim, output_dim, num_tasks, num_epochs=5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains the IndependentLSTM model where each task runs independently.\n",
    "    \"\"\"\n",
    "    model = IndependentLSTM(input_dim, hidden_dim, output_dim, num_tasks).to(device)\n",
    "    optimizers = [torch.optim.Adam(m.parameters(), lr=0.001) for m in model.models]\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for task_id, (train_loader, _, _) in enumerate(site_loaders):\n",
    "            model.models[task_id].train()\n",
    "            train_losses = []\n",
    "\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizers[task_id].zero_grad()\n",
    "                lstm_out, _ = model.models[task_id][0](X)\n",
    "                preds = model.models[task_id][1](lstm_out[:, -1, :])\n",
    "                loss = criterion(preds, y.view(y.size(0), -1))\n",
    "                loss.backward()\n",
    "                optimizers[task_id].step()\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs} | Task {task_id + 1} | Train Loss: {np.mean(train_losses):.4f}\")\n",
    "\n",
    "    print(\"Independent LSTM training complete.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_independent_lstm(model, site_loaders, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates the IndependentLSTM model and computes MAE for each task.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    mae_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for task_id, (_, _, test_loader) in enumerate(site_loaders):\n",
    "            all_preds, all_targets = [], []\n",
    "\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                lstm_out, _ = model.models[task_id][0](X)\n",
    "                preds = model.models[task_id][1](lstm_out[:, -1, :])\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_targets.append(y.cpu().numpy())\n",
    "\n",
    "            preds_concat = np.concatenate(all_preds, axis=0)\n",
    "            targets_concat = np.concatenate(all_targets, axis=0)\n",
    "            mae = mean_absolute_error(targets_concat, preds_concat)\n",
    "            mae_scores.append(mae)\n",
    "            print(f\"Task {task_id + 1} - Independent LSTM MAE: {mae:.4f}\")\n",
    "\n",
    "    print(\"Independent LSTM evaluation complete.\")\n",
    "    return mae_scores\n",
    "\n",
    "\n",
    "def plot_independent_lstm_predictions(model, site_loaders, device='cpu'):\n",
    "    \"\"\"\n",
    "    Plots predictions vs. ground truth for each task in the IndependentLSTM model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    for task_id, (_, _, test_loader) in enumerate(site_loaders):\n",
    "        all_preds, all_truths = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                lstm_out, _ = model.models[task_id][0](X)\n",
    "                preds = model.models[task_id][1](lstm_out[:, -1, :])\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_truths.append(y.cpu().numpy())\n",
    "\n",
    "        preds_concat = np.concatenate(all_preds, axis=0).flatten()\n",
    "        truths_concat = np.concatenate(all_truths, axis=0).flatten()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(truths_concat, label=\"Ground Truth\", linewidth=1)\n",
    "        plt.plot(preds_concat, label=\"Independent LSTM Prediction\", linewidth=1, linestyle='--')\n",
    "        plt.title(f\"Independent LSTM - Task {task_id + 1}: Predictions vs Ground Truth\")\n",
    "        plt.xlabel(\"Sample Index\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ------------------ TRAINING PIPELINE FOR INDEPENDENT LSTM ------------------\n",
    "\n",
    "def run_independent_lstm_pipeline(datasets, horizons, device='cpu'):\n",
    "    \"\"\"\n",
    "    Runs the full training, evaluation, and plotting pipeline for the IndependentLSTM model.\n",
    "    \"\"\"\n",
    "    for dataset in datasets:\n",
    "        print(f\"\\n==================== 🌟 DATASET: {dataset['ds']} ====================\")\n",
    "        for horizon in horizons:\n",
    "            print(f\"\\n==================== ⏳ HORIZON: {horizon} ====================\")\n",
    "\n",
    "            site_paths = [\n",
    "                os.path.join(root, file)\n",
    "                for root, dirs, files in os.walk(dataset['base_path'])\n",
    "                if root != dataset['base_path']\n",
    "                for file in files\n",
    "                if file.endswith(\".csv\")\n",
    "            ]\n",
    "\n",
    "            total_sites = len(site_paths)\n",
    "            num_tasks = total_sites\n",
    "            batch_size, window_size, input_dim, hidden_dim, output_dim = 32, 32, len(dataset['features']), 64, horizon\n",
    "\n",
    "            site_loaders = [\n",
    "                load_and_preprocess_site_data(\n",
    "                    site_path,\n",
    "                    dataset['features'],\n",
    "                    dataset['target'],\n",
    "                    window_size,\n",
    "                    horizon=output_dim,\n",
    "                    batch_size=batch_size,\n",
    "                    min_date=dataset['min_date'],\n",
    "                    max_date=dataset['max_date']\n",
    "                ) for site_path in site_paths\n",
    "            ]\n",
    "\n",
    "            # Training Independent LSTM model\n",
    "            independent_lstm_model = train_independent_lstm(site_loaders, input_dim, hidden_dim, output_dim, num_tasks, num_epochs=5, device=device)\n",
    "            # Evaluating Independent LSTM model\n",
    "            independent_lstm_mae = evaluate_independent_lstm(independent_lstm_model, site_loaders, device=device)\n",
    "            # Plotting predictions\n",
    "            # plot_independent_lstm_predictions(independent_lstm_model, site_loaders, device=device)\n",
    "\n",
    "            print(f\"✅ Completed: {dataset['ds']} | Horizon: {horizon} | Independent LSTM MAE per task: {independent_lstm_mae}\")\n",
    "\n",
    "    print(\"\\n🏆 All Independent LSTM experiments completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 🌟 DATASET: Air Quality_feb_22 ====================\n",
      "\n",
      "==================== ⏳ HORIZON: 1 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Task 1 | Train Loss: 0.5388\n",
      "Epoch 1/5 | Task 2 | Train Loss: 0.6282\n",
      "Epoch 1/5 | Task 3 | Train Loss: 0.4920\n",
      "Epoch 1/5 | Task 4 | Train Loss: 0.5408\n",
      "Epoch 1/5 | Task 5 | Train Loss: 0.5805\n",
      "Epoch 1/5 | Task 6 | Train Loss: 0.5981\n",
      "Epoch 1/5 | Task 7 | Train Loss: 0.5582\n",
      "Epoch 1/5 | Task 8 | Train Loss: 0.4158\n",
      "Epoch 1/5 | Task 9 | Train Loss: 0.5669\n",
      "Epoch 1/5 | Task 10 | Train Loss: 0.5459\n",
      "Epoch 1/5 | Task 11 | Train Loss: 0.5859\n",
      "Epoch 1/5 | Task 12 | Train Loss: 0.5529\n",
      "Epoch 2/5 | Task 1 | Train Loss: 0.1272\n",
      "Epoch 2/5 | Task 2 | Train Loss: 0.1817\n",
      "Epoch 2/5 | Task 3 | Train Loss: 0.1061\n",
      "Epoch 2/5 | Task 4 | Train Loss: 0.1154\n",
      "Epoch 2/5 | Task 5 | Train Loss: 0.1532\n",
      "Epoch 2/5 | Task 6 | Train Loss: 0.1604\n",
      "Epoch 2/5 | Task 7 | Train Loss: 0.1888\n",
      "Epoch 2/5 | Task 8 | Train Loss: 0.0961\n",
      "Epoch 2/5 | Task 9 | Train Loss: 0.2227\n",
      "Epoch 2/5 | Task 10 | Train Loss: 0.1307\n",
      "Epoch 2/5 | Task 11 | Train Loss: 0.1835\n",
      "Epoch 2/5 | Task 12 | Train Loss: 0.1644\n",
      "Epoch 3/5 | Task 1 | Train Loss: 0.0890\n",
      "Epoch 3/5 | Task 2 | Train Loss: 0.1133\n",
      "Epoch 3/5 | Task 3 | Train Loss: 0.0803\n",
      "Epoch 3/5 | Task 4 | Train Loss: 0.0676\n",
      "Epoch 3/5 | Task 5 | Train Loss: 0.0959\n",
      "Epoch 3/5 | Task 6 | Train Loss: 0.1014\n",
      "Epoch 3/5 | Task 7 | Train Loss: 0.1168\n",
      "Epoch 3/5 | Task 8 | Train Loss: 0.0601\n",
      "Epoch 3/5 | Task 9 | Train Loss: 0.1572\n",
      "Epoch 3/5 | Task 10 | Train Loss: 0.0959\n",
      "Epoch 3/5 | Task 11 | Train Loss: 0.1224\n",
      "Epoch 3/5 | Task 12 | Train Loss: 0.1202\n",
      "Epoch 4/5 | Task 1 | Train Loss: 0.0706\n",
      "Epoch 4/5 | Task 2 | Train Loss: 0.0864\n",
      "Epoch 4/5 | Task 3 | Train Loss: 0.0692\n",
      "Epoch 4/5 | Task 4 | Train Loss: 0.0583\n",
      "Epoch 4/5 | Task 5 | Train Loss: 0.0778\n",
      "Epoch 4/5 | Task 6 | Train Loss: 0.0802\n",
      "Epoch 4/5 | Task 7 | Train Loss: 0.0895\n",
      "Epoch 4/5 | Task 8 | Train Loss: 0.0527\n",
      "Epoch 4/5 | Task 9 | Train Loss: 0.1167\n",
      "Epoch 4/5 | Task 10 | Train Loss: 0.0768\n",
      "Epoch 4/5 | Task 11 | Train Loss: 0.1034\n",
      "Epoch 4/5 | Task 12 | Train Loss: 0.0895\n",
      "Epoch 5/5 | Task 1 | Train Loss: 0.0626\n",
      "Epoch 5/5 | Task 2 | Train Loss: 0.0657\n",
      "Epoch 5/5 | Task 3 | Train Loss: 0.0585\n",
      "Epoch 5/5 | Task 4 | Train Loss: 0.0542\n",
      "Epoch 5/5 | Task 5 | Train Loss: 0.0654\n",
      "Epoch 5/5 | Task 6 | Train Loss: 0.0690\n",
      "Epoch 5/5 | Task 7 | Train Loss: 0.0677\n",
      "Epoch 5/5 | Task 8 | Train Loss: 0.0422\n",
      "Epoch 5/5 | Task 9 | Train Loss: 0.0972\n",
      "Epoch 5/5 | Task 10 | Train Loss: 0.0634\n",
      "Epoch 5/5 | Task 11 | Train Loss: 0.0893\n",
      "Epoch 5/5 | Task 12 | Train Loss: 0.0768\n",
      "Independent LSTM training complete.\n",
      "Task 1 - Independent LSTM MAE: 0.1701\n",
      "Task 2 - Independent LSTM MAE: 0.1621\n",
      "Task 3 - Independent LSTM MAE: 0.1545\n",
      "Task 4 - Independent LSTM MAE: 0.1390\n",
      "Task 5 - Independent LSTM MAE: 0.1292\n",
      "Task 6 - Independent LSTM MAE: 0.1987\n",
      "Task 7 - Independent LSTM MAE: 0.1584\n",
      "Task 8 - Independent LSTM MAE: 0.1165\n",
      "Task 9 - Independent LSTM MAE: 0.1664\n",
      "Task 10 - Independent LSTM MAE: 0.2124\n",
      "Task 11 - Independent LSTM MAE: 0.1896\n",
      "Task 12 - Independent LSTM MAE: 0.1580\n",
      "Independent LSTM evaluation complete.\n",
      "✅ Completed: Air Quality_feb_22 | Horizon: 1 | Independent LSTM MAE per task: [0.17011195, 0.16213304, 0.15448499, 0.13898881, 0.12918729, 0.19873953, 0.15838654, 0.116517335, 0.16636845, 0.2124377, 0.18957216, 0.15802635]\n",
      "\n",
      "==================== ⏳ HORIZON: 2 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Task 1 | Train Loss: 0.5733\n",
      "Epoch 1/5 | Task 2 | Train Loss: 0.7059\n",
      "Epoch 1/5 | Task 3 | Train Loss: 0.5523\n",
      "Epoch 1/5 | Task 4 | Train Loss: 0.7491\n",
      "Epoch 1/5 | Task 5 | Train Loss: 0.7685\n",
      "Epoch 1/5 | Task 6 | Train Loss: 0.6524\n",
      "Epoch 1/5 | Task 7 | Train Loss: 0.7320\n",
      "Epoch 1/5 | Task 8 | Train Loss: 0.6558\n",
      "Epoch 1/5 | Task 9 | Train Loss: 0.6835\n",
      "Epoch 1/5 | Task 10 | Train Loss: 0.5849\n",
      "Epoch 1/5 | Task 11 | Train Loss: 0.7372\n",
      "Epoch 1/5 | Task 12 | Train Loss: 0.6492\n",
      "Epoch 2/5 | Task 1 | Train Loss: 0.1649\n",
      "Epoch 2/5 | Task 2 | Train Loss: 0.2521\n",
      "Epoch 2/5 | Task 3 | Train Loss: 0.1432\n",
      "Epoch 2/5 | Task 4 | Train Loss: 0.1955\n",
      "Epoch 2/5 | Task 5 | Train Loss: 0.2554\n",
      "Epoch 2/5 | Task 6 | Train Loss: 0.2080\n",
      "Epoch 2/5 | Task 7 | Train Loss: 0.2396\n",
      "Epoch 2/5 | Task 8 | Train Loss: 0.1643\n",
      "Epoch 2/5 | Task 9 | Train Loss: 0.2379\n",
      "Epoch 2/5 | Task 10 | Train Loss: 0.1726\n",
      "Epoch 2/5 | Task 11 | Train Loss: 0.2701\n",
      "Epoch 2/5 | Task 12 | Train Loss: 0.1879\n",
      "Epoch 3/5 | Task 1 | Train Loss: 0.1167\n",
      "Epoch 3/5 | Task 2 | Train Loss: 0.1461\n",
      "Epoch 3/5 | Task 3 | Train Loss: 0.0883\n",
      "Epoch 3/5 | Task 4 | Train Loss: 0.0913\n",
      "Epoch 3/5 | Task 5 | Train Loss: 0.1323\n",
      "Epoch 3/5 | Task 6 | Train Loss: 0.1351\n",
      "Epoch 3/5 | Task 7 | Train Loss: 0.1461\n",
      "Epoch 3/5 | Task 8 | Train Loss: 0.0906\n",
      "Epoch 3/5 | Task 9 | Train Loss: 0.1798\n",
      "Epoch 3/5 | Task 10 | Train Loss: 0.1205\n",
      "Epoch 3/5 | Task 11 | Train Loss: 0.1638\n",
      "Epoch 3/5 | Task 12 | Train Loss: 0.1193\n",
      "Epoch 4/5 | Task 1 | Train Loss: 0.0952\n",
      "Epoch 4/5 | Task 2 | Train Loss: 0.1141\n",
      "Epoch 4/5 | Task 3 | Train Loss: 0.0874\n",
      "Epoch 4/5 | Task 4 | Train Loss: 0.0759\n",
      "Epoch 4/5 | Task 5 | Train Loss: 0.1051\n",
      "Epoch 4/5 | Task 6 | Train Loss: 0.1104\n",
      "Epoch 4/5 | Task 7 | Train Loss: 0.1127\n",
      "Epoch 4/5 | Task 8 | Train Loss: 0.0691\n",
      "Epoch 4/5 | Task 9 | Train Loss: 0.1512\n",
      "Epoch 4/5 | Task 10 | Train Loss: 0.0981\n",
      "Epoch 4/5 | Task 11 | Train Loss: 0.1400\n",
      "Epoch 4/5 | Task 12 | Train Loss: 0.1037\n",
      "Epoch 5/5 | Task 1 | Train Loss: 0.0866\n",
      "Epoch 5/5 | Task 2 | Train Loss: 0.0986\n",
      "Epoch 5/5 | Task 3 | Train Loss: 0.0784\n",
      "Epoch 5/5 | Task 4 | Train Loss: 0.0668\n",
      "Epoch 5/5 | Task 5 | Train Loss: 0.0885\n",
      "Epoch 5/5 | Task 6 | Train Loss: 0.0941\n",
      "Epoch 5/5 | Task 7 | Train Loss: 0.0909\n",
      "Epoch 5/5 | Task 8 | Train Loss: 0.0623\n",
      "Epoch 5/5 | Task 9 | Train Loss: 0.1267\n",
      "Epoch 5/5 | Task 10 | Train Loss: 0.0882\n",
      "Epoch 5/5 | Task 11 | Train Loss: 0.1206\n",
      "Epoch 5/5 | Task 12 | Train Loss: 0.0934\n",
      "Independent LSTM training complete.\n",
      "Task 1 - Independent LSTM MAE: 0.2048\n",
      "Task 2 - Independent LSTM MAE: 0.1952\n",
      "Task 3 - Independent LSTM MAE: 0.1917\n",
      "Task 4 - Independent LSTM MAE: 0.1628\n",
      "Task 5 - Independent LSTM MAE: 0.1706\n",
      "Task 6 - Independent LSTM MAE: 0.2115\n",
      "Task 7 - Independent LSTM MAE: 0.2141\n",
      "Task 8 - Independent LSTM MAE: 0.1511\n",
      "Task 9 - Independent LSTM MAE: 0.1919\n",
      "Task 10 - Independent LSTM MAE: 0.2255\n",
      "Task 11 - Independent LSTM MAE: 0.2023\n",
      "Task 12 - Independent LSTM MAE: 0.1874\n",
      "Independent LSTM evaluation complete.\n",
      "✅ Completed: Air Quality_feb_22 | Horizon: 2 | Independent LSTM MAE per task: [0.20482785, 0.19523138, 0.19166583, 0.16279426, 0.17061627, 0.21151462, 0.21406454, 0.15105566, 0.1919233, 0.22546855, 0.20230404, 0.18739253]\n",
      "\n",
      "==================== ⏳ HORIZON: 4 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Task 1 | Train Loss: 0.7885\n",
      "Epoch 1/5 | Task 2 | Train Loss: 0.7283\n",
      "Epoch 1/5 | Task 3 | Train Loss: 0.6639\n",
      "Epoch 1/5 | Task 4 | Train Loss: 0.6503\n",
      "Epoch 1/5 | Task 5 | Train Loss: 0.7742\n",
      "Epoch 1/5 | Task 6 | Train Loss: 0.8053\n",
      "Epoch 1/5 | Task 7 | Train Loss: 0.7520\n",
      "Epoch 1/5 | Task 8 | Train Loss: 0.6936\n",
      "Epoch 1/5 | Task 9 | Train Loss: 0.6903\n",
      "Epoch 1/5 | Task 10 | Train Loss: 0.8000\n",
      "Epoch 1/5 | Task 11 | Train Loss: 0.7603\n",
      "Epoch 1/5 | Task 12 | Train Loss: 0.6727\n",
      "Epoch 2/5 | Task 1 | Train Loss: 0.2921\n",
      "Epoch 2/5 | Task 2 | Train Loss: 0.3148\n",
      "Epoch 2/5 | Task 3 | Train Loss: 0.1976\n",
      "Epoch 2/5 | Task 4 | Train Loss: 0.2122\n",
      "Epoch 2/5 | Task 5 | Train Loss: 0.2864\n",
      "Epoch 2/5 | Task 6 | Train Loss: 0.2956\n",
      "Epoch 2/5 | Task 7 | Train Loss: 0.2744\n",
      "Epoch 2/5 | Task 8 | Train Loss: 0.2175\n",
      "Epoch 2/5 | Task 9 | Train Loss: 0.3110\n",
      "Epoch 2/5 | Task 10 | Train Loss: 0.2958\n",
      "Epoch 2/5 | Task 11 | Train Loss: 0.3048\n",
      "Epoch 2/5 | Task 12 | Train Loss: 0.2702\n",
      "Epoch 3/5 | Task 1 | Train Loss: 0.1816\n",
      "Epoch 3/5 | Task 2 | Train Loss: 0.2020\n",
      "Epoch 3/5 | Task 3 | Train Loss: 0.1267\n",
      "Epoch 3/5 | Task 4 | Train Loss: 0.1226\n",
      "Epoch 3/5 | Task 5 | Train Loss: 0.1779\n",
      "Epoch 3/5 | Task 6 | Train Loss: 0.2017\n",
      "Epoch 3/5 | Task 7 | Train Loss: 0.1775\n",
      "Epoch 3/5 | Task 8 | Train Loss: 0.1302\n",
      "Epoch 3/5 | Task 9 | Train Loss: 0.2359\n",
      "Epoch 3/5 | Task 10 | Train Loss: 0.1727\n",
      "Epoch 3/5 | Task 11 | Train Loss: 0.2131\n",
      "Epoch 3/5 | Task 12 | Train Loss: 0.1887\n",
      "Epoch 4/5 | Task 1 | Train Loss: 0.1530\n",
      "Epoch 4/5 | Task 2 | Train Loss: 0.1733\n",
      "Epoch 4/5 | Task 3 | Train Loss: 0.1166\n",
      "Epoch 4/5 | Task 4 | Train Loss: 0.0932\n",
      "Epoch 4/5 | Task 5 | Train Loss: 0.1522\n",
      "Epoch 4/5 | Task 6 | Train Loss: 0.1629\n",
      "Epoch 4/5 | Task 7 | Train Loss: 0.1468\n",
      "Epoch 4/5 | Task 8 | Train Loss: 0.1170\n",
      "Epoch 4/5 | Task 9 | Train Loss: 0.2052\n",
      "Epoch 4/5 | Task 10 | Train Loss: 0.1510\n",
      "Epoch 4/5 | Task 11 | Train Loss: 0.1955\n",
      "Epoch 4/5 | Task 12 | Train Loss: 0.1525\n",
      "Epoch 5/5 | Task 1 | Train Loss: 0.1315\n",
      "Epoch 5/5 | Task 2 | Train Loss: 0.1562\n",
      "Epoch 5/5 | Task 3 | Train Loss: 0.0958\n",
      "Epoch 5/5 | Task 4 | Train Loss: 0.0882\n",
      "Epoch 5/5 | Task 5 | Train Loss: 0.1339\n",
      "Epoch 5/5 | Task 6 | Train Loss: 0.1453\n",
      "Epoch 5/5 | Task 7 | Train Loss: 0.1330\n",
      "Epoch 5/5 | Task 8 | Train Loss: 0.0911\n",
      "Epoch 5/5 | Task 9 | Train Loss: 0.1938\n",
      "Epoch 5/5 | Task 10 | Train Loss: 0.1305\n",
      "Epoch 5/5 | Task 11 | Train Loss: 0.1835\n",
      "Epoch 5/5 | Task 12 | Train Loss: 0.1394\n",
      "Independent LSTM training complete.\n",
      "Task 1 - Independent LSTM MAE: 0.2364\n",
      "Task 2 - Independent LSTM MAE: 0.3065\n",
      "Task 3 - Independent LSTM MAE: 0.2303\n",
      "Task 4 - Independent LSTM MAE: 0.1883\n",
      "Task 5 - Independent LSTM MAE: 0.2054\n",
      "Task 6 - Independent LSTM MAE: 0.2753\n",
      "Task 7 - Independent LSTM MAE: 0.3009\n",
      "Task 8 - Independent LSTM MAE: 0.1837\n",
      "Task 9 - Independent LSTM MAE: 0.2549\n",
      "Task 10 - Independent LSTM MAE: 0.2748\n",
      "Task 11 - Independent LSTM MAE: 0.2717\n",
      "Task 12 - Independent LSTM MAE: 0.2522\n",
      "Independent LSTM evaluation complete.\n",
      "✅ Completed: Air Quality_feb_22 | Horizon: 4 | Independent LSTM MAE per task: [0.23641592, 0.30650273, 0.23026821, 0.18826486, 0.2053918, 0.2752838, 0.30085325, 0.18372211, 0.2548935, 0.27477556, 0.27173454, 0.25221166]\n",
      "\n",
      "==================== ⏳ HORIZON: 8 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Task 1 | Train Loss: 0.7358\n",
      "Epoch 1/5 | Task 2 | Train Loss: 0.7401\n",
      "Epoch 1/5 | Task 3 | Train Loss: 0.7316\n",
      "Epoch 1/5 | Task 4 | Train Loss: 0.8099\n",
      "Epoch 1/5 | Task 5 | Train Loss: 0.8116\n",
      "Epoch 1/5 | Task 6 | Train Loss: 0.8090\n",
      "Epoch 1/5 | Task 7 | Train Loss: 0.7471\n",
      "Epoch 1/5 | Task 8 | Train Loss: 0.7427\n",
      "Epoch 1/5 | Task 9 | Train Loss: 0.8006\n",
      "Epoch 1/5 | Task 10 | Train Loss: 0.7533\n",
      "Epoch 1/5 | Task 11 | Train Loss: 0.7931\n",
      "Epoch 1/5 | Task 12 | Train Loss: 0.7753\n",
      "Epoch 2/5 | Task 1 | Train Loss: 0.3099\n",
      "Epoch 2/5 | Task 2 | Train Loss: 0.3745\n",
      "Epoch 2/5 | Task 3 | Train Loss: 0.2774\n",
      "Epoch 2/5 | Task 4 | Train Loss: 0.2826\n",
      "Epoch 2/5 | Task 5 | Train Loss: 0.3700\n",
      "Epoch 2/5 | Task 6 | Train Loss: 0.3801\n",
      "Epoch 2/5 | Task 7 | Train Loss: 0.3563\n",
      "Epoch 2/5 | Task 8 | Train Loss: 0.2849\n",
      "Epoch 2/5 | Task 9 | Train Loss: 0.4291\n",
      "Epoch 2/5 | Task 10 | Train Loss: 0.3193\n",
      "Epoch 2/5 | Task 11 | Train Loss: 0.3957\n",
      "Epoch 2/5 | Task 12 | Train Loss: 0.3719\n",
      "Epoch 3/5 | Task 1 | Train Loss: 0.2398\n",
      "Epoch 3/5 | Task 2 | Train Loss: 0.2790\n",
      "Epoch 3/5 | Task 3 | Train Loss: 0.1694\n",
      "Epoch 3/5 | Task 4 | Train Loss: 0.1815\n",
      "Epoch 3/5 | Task 5 | Train Loss: 0.2609\n",
      "Epoch 3/5 | Task 6 | Train Loss: 0.2640\n",
      "Epoch 3/5 | Task 7 | Train Loss: 0.2533\n",
      "Epoch 3/5 | Task 8 | Train Loss: 0.1901\n",
      "Epoch 3/5 | Task 9 | Train Loss: 0.3239\n",
      "Epoch 3/5 | Task 10 | Train Loss: 0.2305\n",
      "Epoch 3/5 | Task 11 | Train Loss: 0.2897\n",
      "Epoch 3/5 | Task 12 | Train Loss: 0.2430\n",
      "Epoch 4/5 | Task 1 | Train Loss: 0.2332\n",
      "Epoch 4/5 | Task 2 | Train Loss: 0.2502\n",
      "Epoch 4/5 | Task 3 | Train Loss: 0.1336\n",
      "Epoch 4/5 | Task 4 | Train Loss: 0.1505\n",
      "Epoch 4/5 | Task 5 | Train Loss: 0.2162\n",
      "Epoch 4/5 | Task 6 | Train Loss: 0.2350\n",
      "Epoch 4/5 | Task 7 | Train Loss: 0.2264\n",
      "Epoch 4/5 | Task 8 | Train Loss: 0.1526\n",
      "Epoch 4/5 | Task 9 | Train Loss: 0.2953\n",
      "Epoch 4/5 | Task 10 | Train Loss: 0.2083\n",
      "Epoch 4/5 | Task 11 | Train Loss: 0.2718\n",
      "Epoch 4/5 | Task 12 | Train Loss: 0.2129\n",
      "Epoch 5/5 | Task 1 | Train Loss: 0.2156\n",
      "Epoch 5/5 | Task 2 | Train Loss: 0.2345\n",
      "Epoch 5/5 | Task 3 | Train Loss: 0.1604\n",
      "Epoch 5/5 | Task 4 | Train Loss: 0.1237\n",
      "Epoch 5/5 | Task 5 | Train Loss: 0.2015\n",
      "Epoch 5/5 | Task 6 | Train Loss: 0.2442\n",
      "Epoch 5/5 | Task 7 | Train Loss: 0.1974\n",
      "Epoch 5/5 | Task 8 | Train Loss: 0.1465\n",
      "Epoch 5/5 | Task 9 | Train Loss: 0.2750\n",
      "Epoch 5/5 | Task 10 | Train Loss: 0.1965\n",
      "Epoch 5/5 | Task 11 | Train Loss: 0.2513\n",
      "Epoch 5/5 | Task 12 | Train Loss: 0.1873\n",
      "Independent LSTM training complete.\n",
      "Task 1 - Independent LSTM MAE: 0.3146\n",
      "Task 2 - Independent LSTM MAE: 0.3820\n",
      "Task 3 - Independent LSTM MAE: 0.2829\n",
      "Task 4 - Independent LSTM MAE: 0.2383\n",
      "Task 5 - Independent LSTM MAE: 0.2795\n",
      "Task 6 - Independent LSTM MAE: 0.3137\n",
      "Task 7 - Independent LSTM MAE: 0.4271\n",
      "Task 8 - Independent LSTM MAE: 0.2631\n",
      "Task 9 - Independent LSTM MAE: 0.4096\n",
      "Task 10 - Independent LSTM MAE: 0.3693\n",
      "Task 11 - Independent LSTM MAE: 0.3619\n",
      "Task 12 - Independent LSTM MAE: 0.3201\n",
      "Independent LSTM evaluation complete.\n",
      "✅ Completed: Air Quality_feb_22 | Horizon: 8 | Independent LSTM MAE per task: [0.31460226, 0.3819707, 0.28293073, 0.23826481, 0.2795016, 0.31374347, 0.42712379, 0.2631158, 0.4096259, 0.36926138, 0.36193514, 0.32005963]\n",
      "\n",
      "==================== ⏳ HORIZON: 16 ====================\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Train size: 1119 | Validation size: 279 | Test size: 350\n",
      "Epoch 1/5 | Task 1 | Train Loss: 0.8652\n",
      "Epoch 1/5 | Task 2 | Train Loss: 0.8167\n",
      "Epoch 1/5 | Task 3 | Train Loss: 0.7907\n",
      "Epoch 1/5 | Task 4 | Train Loss: 0.7980\n",
      "Epoch 1/5 | Task 5 | Train Loss: 0.8392\n",
      "Epoch 1/5 | Task 6 | Train Loss: 0.8147\n",
      "Epoch 1/5 | Task 7 | Train Loss: 0.8715\n",
      "Epoch 1/5 | Task 8 | Train Loss: 0.8370\n",
      "Epoch 1/5 | Task 9 | Train Loss: 0.9142\n",
      "Epoch 1/5 | Task 10 | Train Loss: 0.8307\n",
      "Epoch 1/5 | Task 11 | Train Loss: 0.8785\n",
      "Epoch 1/5 | Task 12 | Train Loss: 0.8655\n",
      "Epoch 2/5 | Task 1 | Train Loss: 0.4196\n",
      "Epoch 2/5 | Task 2 | Train Loss: 0.4587\n",
      "Epoch 2/5 | Task 3 | Train Loss: 0.3973\n",
      "Epoch 2/5 | Task 4 | Train Loss: 0.3831\n",
      "Epoch 2/5 | Task 5 | Train Loss: 0.4565\n",
      "Epoch 2/5 | Task 6 | Train Loss: 0.4549\n",
      "Epoch 2/5 | Task 7 | Train Loss: 0.4682\n",
      "Epoch 2/5 | Task 8 | Train Loss: 0.4360\n",
      "Epoch 2/5 | Task 9 | Train Loss: 0.5564\n",
      "Epoch 2/5 | Task 10 | Train Loss: 0.4085\n",
      "Epoch 2/5 | Task 11 | Train Loss: 0.4963\n",
      "Epoch 2/5 | Task 12 | Train Loss: 0.4488\n",
      "Epoch 3/5 | Task 1 | Train Loss: 0.3432\n",
      "Epoch 3/5 | Task 2 | Train Loss: 0.3563\n",
      "Epoch 3/5 | Task 3 | Train Loss: 0.2818\n",
      "Epoch 3/5 | Task 4 | Train Loss: 0.2752\n",
      "Epoch 3/5 | Task 5 | Train Loss: 0.3395\n",
      "Epoch 3/5 | Task 6 | Train Loss: 0.3760\n",
      "Epoch 3/5 | Task 7 | Train Loss: 0.3401\n",
      "Epoch 3/5 | Task 8 | Train Loss: 0.3267\n",
      "Epoch 3/5 | Task 9 | Train Loss: 0.4477\n",
      "Epoch 3/5 | Task 10 | Train Loss: 0.3023\n",
      "Epoch 3/5 | Task 11 | Train Loss: 0.3902\n",
      "Epoch 3/5 | Task 12 | Train Loss: 0.3542\n",
      "Epoch 4/5 | Task 1 | Train Loss: 0.3147\n",
      "Epoch 4/5 | Task 2 | Train Loss: 0.3374\n",
      "Epoch 4/5 | Task 3 | Train Loss: 0.2259\n",
      "Epoch 4/5 | Task 4 | Train Loss: 0.2192\n",
      "Epoch 4/5 | Task 5 | Train Loss: 0.2994\n",
      "Epoch 4/5 | Task 6 | Train Loss: 0.3579\n",
      "Epoch 4/5 | Task 7 | Train Loss: 0.2707\n",
      "Epoch 4/5 | Task 8 | Train Loss: 0.2598\n",
      "Epoch 4/5 | Task 9 | Train Loss: 0.4065\n",
      "Epoch 4/5 | Task 10 | Train Loss: 0.2814\n",
      "Epoch 4/5 | Task 11 | Train Loss: 0.3645\n",
      "Epoch 4/5 | Task 12 | Train Loss: 0.3165\n",
      "Epoch 5/5 | Task 1 | Train Loss: 0.3125\n",
      "Epoch 5/5 | Task 2 | Train Loss: 0.3223\n",
      "Epoch 5/5 | Task 3 | Train Loss: 0.2225\n",
      "Epoch 5/5 | Task 4 | Train Loss: 0.1787\n",
      "Epoch 5/5 | Task 5 | Train Loss: 0.2601\n",
      "Epoch 5/5 | Task 6 | Train Loss: 0.3311\n",
      "Epoch 5/5 | Task 7 | Train Loss: 0.2402\n",
      "Epoch 5/5 | Task 8 | Train Loss: 0.1987\n",
      "Epoch 5/5 | Task 9 | Train Loss: 0.3895\n",
      "Epoch 5/5 | Task 10 | Train Loss: 0.2585\n",
      "Epoch 5/5 | Task 11 | Train Loss: 0.3340\n",
      "Epoch 5/5 | Task 12 | Train Loss: 0.2815\n",
      "Independent LSTM training complete.\n",
      "Task 1 - Independent LSTM MAE: 0.3527\n",
      "Task 2 - Independent LSTM MAE: 0.4650\n",
      "Task 3 - Independent LSTM MAE: 0.3398\n",
      "Task 4 - Independent LSTM MAE: 0.3089\n",
      "Task 5 - Independent LSTM MAE: 0.3812\n",
      "Task 6 - Independent LSTM MAE: 0.3728\n",
      "Task 7 - Independent LSTM MAE: 0.4789\n",
      "Task 8 - Independent LSTM MAE: 0.3603\n",
      "Task 9 - Independent LSTM MAE: 0.4813\n",
      "Task 10 - Independent LSTM MAE: 0.5572\n",
      "Task 11 - Independent LSTM MAE: 0.4657\n",
      "Task 12 - Independent LSTM MAE: 0.4307\n",
      "Independent LSTM evaluation complete.\n",
      "✅ Completed: Air Quality_feb_22 | Horizon: 16 | Independent LSTM MAE per task: [0.3527447, 0.46503824, 0.33980906, 0.3089484, 0.381237, 0.37282836, 0.47886476, 0.36029565, 0.48131606, 0.55722743, 0.4656592, 0.43069828]\n",
      "\n",
      "🏆 All Independent LSTM experiments completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "run_independent_lstm_pipeline(datasets=datasets, horizons=horizons, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centralized",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
